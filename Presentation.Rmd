---
title: "Clustering GAM-Smoothed NFL Elo Ratings"
subtitle: "STAT 448: Mixed Models"
author: "Paul Harmon"
date: "Fall 2017"
output:
  beamer_presentation:
    theme: "CambridgeUS"
    colortheme: "crane"
    fonttheme: "serif"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(dplyr)
library(readr); library(mgcv);library(pander)
x <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/nfl-elo-game/master/data/nfl_games.csv")
x_new <- dplyr::filter(x, season > 2001) #filters out anything before 2002, when Texans joined the league
#mutate some new columns
x_1 <- x_new[,c("date","season","team1","elo1","playoff")]
x_2 <- x_new[,c("date","season","team2","elo2","playoff")]
names(x_1) <- names(x_2) <- c("date","season","team","elo","playoff")
x_full <- rbind(x_1,x_2)

#remove playoff games
x_np <- arrange(dplyr::filter(x_full, playoff == 0), date)
x_np$teamyear <- interaction(x_np$season,x_np$team)

#some commentary: it looks like these are, in a certain sense, marginal models for the average
#elo of the team during a given year. 
#Try to create a "long" dataset
#Structure - Observations of every game for each year for each team as rows
x_sort <- arrange(x_np, teamyear) #sort so I can add a game indicator by team/game
x_sort$GAME <- rep(c(1:16),32*15) #adds a game indicator for each variable

write.csv(x_sort,"elo.long.csv")
#that game variable will become a column
library(tidyr)
x_wide <- x_sort[,c(2,3,4,7)]%>% spread(key = GAME, value = elo) #check it out I put in a pipe operator!
#we have a wide dataset, can i fit gam to each season

game <- 1:16
x <- gam(unlist(x_wide[1,-c(1,2)])~s(game, k=4), bs = 'cs')
gam_Wide <- function(vector, gam.type = 'cs', max.df = 16){
  #create game variable
  game <- 1:16
  #takes a wide dataset (remove name and year first)
  x <- gam(unlist(vector) ~ s(game, k = max.df))
  
return(x)}

gam_list <- apply(x_wide[,-c(1,2)],1,gam_Wide) #returns a list of the stuff you need
names(gam_list) <- interaction(x_wide$season,x_wide$team)
x_wide$teamyear <- interaction(x_wide$season,x_wide$team)
#let's make a data frame of predicted gams
pred_mat <- matrix(0, nrow = length(gam_list), ncol = 16)
for(j in 1:length(gam_list)){
pred_mat[j,] <- predict(gam_list[[j]])  
}
rownames(pred_mat) <- names(gam_list)

#create dissimilarity matrix via R-package (although below might be interesting as well)
#uses L2 norm (Euclidean distances) but I'd be curious about Mahalonobis distances as well
library(fda.usc)
gam_distances <- metric.lp(pred_mat)

#let's go ahead and try some hierarchical clustering
library(mclust)
#is there a way to do medoid-based clustering?
library(cluster)
pam1 <- pam(as.dist(gam_distances), metric = "euclidean", k = 4)

#tables of clusters


```

##Introduction: What's the Big Deal?

My goal was to analyze trends in NFL team wining/losing behavior over time. The NFL is supposed to have __parity__, meaning that good teams eventually become bad teams and vice versa. But that isn't always the case in the short term - say, 20 year periods. The Bills haven't made the playoffs in 18 years. The Patriots have missed the playoffs just three times in that span.

The goal started as simply trying to cluster teams based on their behavior during the season, as ranked by their Elo rating. (We'll get to that...). However, several other questions quickly arose:

+ Do you need to know about all 16 games to classify a team's behavior during the season? Or do teams "reveal themselves" before the season is totally over?
+ How sensitive are clusters to smoothing bases?
+ How many clusters should there be? I think 4, but that's a totally subjective starting point. 
+ How sensitive are clusters to the clustering method? (Hierarchical vs. Medoid-based)


##What Are Elo Ratings?
Elo ratings are used by FiveThirtyEight to predict the outcome of head-to-head matchups between NFL teams. They were originally developed for prediction of chess matches but have been extended to sports analytics.

+ A way to rank teams and predict outcomes 
+ Teams with higher Elo Ratings should beat teams with lower Elo Ratings
+ Can be interpreted as point spreads for matchups (divide difference by 25 to get spread)
+ Average Elo is 1500 for an NFL team, and they are calculated prior to every game

##Elo Ratings: In Depth

In general, an Elo rating can be calulated as a function of three things: a __Previous Elo Score__, a __Per-Game Weighting Factor__, and a __Margin of Victory Factor__.  The cool feature of Elo ratings is that they can reflect the increased effect of a single game during a 16-game NFL season as compared to an 82-game NBA season, or 144-game MLB season. 

__A General Elo Formula:__
$$ R_t = R_{t-1}+ K*V*M_{ij}(S_{ij}-\mu_{ij}) $$


##Why Do We Care About Classifying Elo Ratings?
Team decision makers may want to develop a sense for the type of team that they have, given that not all teams realistically have a chance at  winning a championship in every year. Sorry, Broncos and Browns fans...

+ We want to make __comparisons__ between different teams in different seasons. 
+ Allows for assessment of team __parity__ over time. 

__Goal__: To __smooth__ season-long measurements of Elo ratings for each NFL team and __cluster__ team-year Elos into 4 groups.  Research by Hitchcock, Booth, and yes, _that_ George Casella (2007) indicates that smoothing improves cluster fits.


##The Data
We have __32 teams__ with 16 games per season over 15 seasons, leading to 480 curves that need to be smoothed with GAMs. Each team/year combination is considered independent. 

```{r plot_elo, eval = TRUE, fig.align = 'center', fig.width = 8, fig.height = 4}
ggplot(filter(x_sort, teamyear %in% c('2012.DEN','2007.NE','2008.DET','2016.NE'))) + 
  geom_line(aes(x = GAME, y = elo, group = teamyear,col = teamyear),lwd = 2) +
  theme_bw() + xlab("Game") + ylab("Elo Rating") + ggtitle("Four Teams' Elo Ratings") + 
  scale_color_manual(values=c("orange", "lightblue", "red","blue4"))
```


##GAM-Smoothed Estimates

+ Elo Ratings can be noisy! It might be better to estimate a mean trend. 
+ I used GAMS to estimate smooth versions of these noisy trends in Elo.

__A Very Complicated Model: __ 
$$ \hat{Elo}_{ij} = s_{i}(game_{ij})$$
_Notationally, i refers to team/year combination (1..480) and j refers to game within season (1...16)._  

+ Technically, there are 480 smoothed models fit here
+ They may involve differing EDFs for each model depending on how wiggly things need to be
+ Majority of the EDF were below 5.72, with 90 percent having small p-values

```{r, include = FALSE}
pval_get <- function(gam.object){
  smooth_pval <- summary(gam.object)$s.pv
  
 return(s.pval = smooth_pval)}

edf_get <- function(gam.object){
  edf <- summary(gam.object)$edf
  return(edf = edf)}

edf_values <- sapply(gam_list, edf_get)
summary(edf_values)

p_values <- sapply(gam_list, pval_get)
summary(p_values)
```


##Functional Data clustering: 4-Cluster Solution
__Contenders__: 2010 Baltimore Ravens, __Status Quo__: 2010 Miami Dolphins, __Pretenders__: 2009 Buffalo Bills, __Loveable Losers__: 2008 Oakland Raiders

```{r,warning = FALSE, message = FALSE, eval = TRUE, fig.align = 'center', fig.width = 6, fig.height = 2.5}

ggplot(filter(x_sort, teamyear %in% pam1$medoids)) + 
  geom_line(aes(x = GAME, y = elo, group = teamyear,col = teamyear),lwd = 1.2) +
  theme_bw() + xlab("Game") + ylab("Elo Rating") + ggtitle("Medoid Elo Ratings") + 
  scale_color_manual(values=c("orange", "lightblue", "red","blue4"))


```


##Selected References

Glickman, Mark E. and Jones, Albyn (1999)."Rating the Chess Rating System". _Chance_. pp.21-28.

Silver,Nate (2014). "Introducing NFL Elo Ratings" _https://fivethirtyeight.com/features/introducing-nfl-elo-ratings_

Hitchcock, David B., Booth, James G., and Casella, George. (2007). "The Effect of Pre-Smoothing Functional Data on Cluster Analysis." _The Journal of Statistical Computation and Simulation_. 
pp. 1043-1055.

Wood, Simon.(2017). _Generalized Additive Models: An Introduction with R_. Ed 2.Chapman and Hall/CRC. 


##Questions

![ ](figure/siemian.jpg)

##Supplementary Slides
Why not model long-term trends? We could ignore the fact that the Elos are normalized and try to model the long-term trends if we wanted to. 
```{r, warning = FALSE, message = FALSE, fig.align = 'center', fig.height = 4}
plot(x_np$date[x_np$team == "DEN"],x_np$elo[x_np$team == "DEN"], type = "p", xlab = "Year", ylab = "ELO", pch = 20, col = "orange2")
title("Denver Broncos Elos since 2002")

library(mgcv)
den.dat <- x_np[x_np$team == "DEN",]
gam1 <- gam(elo ~ s(as.numeric(date), k = 16), data = den.dat) #tensor product
gam2 <- gam(elo ~ s(as.numeric(date), k = 16, bs = "cs"), data = den.dat) #cubicshrinkage
gam3 <- gam(elo ~ s(as.numeric(date), k = 16, bs = "ds"), data = den.dat)
gam4 <- gam(elo ~ s(as.numeric(date), k = 16, bs = "cr"), data = den.dat)

gamm1 <- gamm(elo ~ s(as.numeric(date), k = 16, bs = "cs"), random = , data = den.dat)

lines(den.dat$date, predict(gam1), col = "blue3", lwd = 2)
lines(den.dat$date, predict(gam2), col = "red", lwd = 2, lty = 3)
lines(den.dat$date, predict(gam3), col = "pink", lwd = 2, lty = 4)
lines(den.dat$date, predict(gam4), col = "purple", lwd = 2, lty = 2)

legend('bottomright', legend = c("TP","CS","DS","CR"), fill = c("blue3","red","pink","purple"))
```


##Some Interesting Team Results
```{r}
pander(table(x_wide$team,pam1$clustering)[c(4,10,21,23),])
```

##Functional Data Clustering
We can then take these curves and calculate distances between each of the GAM smoothers. We can generate a 4-cluster solution based on a technique called __Partitioning Around Medoids__ (PAM). 
The Idea: 

+ Determine 4 "medoid" GAM fits
+ For each GAM, figure out which medoid is closest - that's the cluster that each observation goes in

##Why Smooth?
Goal: To __smooth__ season-long measurements of Elo ratings for each NFL team and __cluster__ team-year Elos into 4 groups.  Research by Hitchcock, Booth, and Casella (2007) indicates that smoothing improves cluster fits. 

```{r, fig.align = 'center', fig.width = 6, fig.height = 4}
plot(1:16,predict(gam_list[[472]]), type = "l", xlab = "Game", ylab = "Elo", lwd = 2, col = "red3")
points(1:16, x_wide[472,-c(1,2,19)], col = "green3", pch = 18, cex = 1.2)
title("New York Jets 2016 Data vs. Smooth GAM")
```
